\section{Conclusion}

\subsection{What}
We studied whether it is possible to build a classifier working with binary values directly at binary level. Concretely, we tried out 2 different schemes, LUT networks and AIGs, where we found that LUT networks can be built in reasonable time, have reasonable performance and given the right architecture choice take up little space on disk. AIGs also have to potential to work as binary classifiers. We introduced what AIGs are and presented an initialization and learning scheme.

\subsection{How}
We introduced the concept of LUTs from \cite{bib:chatterjee2018learning}, recreated results from the paper and consequently tried to improve LUT-based architectures by inventing new schemes. In Section~\ref{sec:models} we have seen inferior performance of LUT networks on Binary-MNIST compared to a CNN. However, we were able to improve performance significantly in Section~\ref{sec:ada_boost}, not to the extent to the CNN, but perhaps with more research, the performance of LUT-based models can be increased even further. When it comes to model size, the choice of architecture matters a lot in LUT networks. Especially the bit-size is crucial; since the size of a LUT table is exponentially proportional to the bit size, a too large bit size quickly increases size on disk with questionable improvement in performance, see Section~\ref{sec:models}. As we have seen in Section~\ref{sec:num_luts_per_layer}, we can significantly decrease the nubmer of LUTs per hidden layer in a LUT network without much loss of accuracy. Making a good choice of architecture, combined with ensembling techniques results in LUT-based models that are comparitively small. One other thing we should note is that LUT-based models lack the need for matrix operations as opposed to neural networks which could result in increased inference speed.

We introduced AIGs and investigated whether or not they can be used to predict something, where we have found out that the use of AIGs as classifiers that are trained like a regular machine learning model seems possible. We, however, found much lower performance than LUT networks which we think is due to 3 main reasons: possibly sub-optimal initialization, a too na√Øve learning algorithm and a search algorithm implementation that lacks optimization, especially multi-processing. Perhaps given more research, performance can be significantly increased. Since we devised initialization, learning and the implementation from scratch, we think that there is much room for improvement.

\subsection{Future Work}
Further increasing the accuracy of LUT-based models is key for making them viable for popular use. Section~\ref{sec:ada_boost} gives a hint that LUT-based models could give a powerful performance. A proper LUT framework that runs fast (e.g., C++ instead of Python), is easy to use and also suitable for production environment could help introducing the idea of LUTs to a wider audience. What we have not investigated is if LUTs could be used as an intermediate representation of circuits. Also, if LUTs can be implemented easily on hardware. When it comes to AIGs as classifiers, a proper initialization and learning algorithm have yet to be devised. AIGs as classifiers definitely have potential, but we are yet unsure how much.
